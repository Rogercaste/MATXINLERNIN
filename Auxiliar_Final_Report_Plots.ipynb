{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rogercaste/MATXINLERNIN/blob/master/Auxiliar_Final_Report_Plots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Starting: Imports, modules, and paths"
      ],
      "metadata": {
        "id": "fSGPn4WK3CXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sMezSu32q6z",
        "outputId": "f0830e91-64ef-474e-9416-b92f3a19e821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Drive Mount:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs:\n",
        "!pip install hsemotion\n",
        "!pip install moviepy\n",
        "!pip3 install imageio==2.4.1\n",
        "!pip install --upgrade imageio-ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAsXhSqp3Hw1",
        "outputId": "b45e03e3-9ec9-47ee-f508-e14f25735086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hsemotion\n",
            "  Downloading hsemotion-0.3.0.tar.gz (8.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hsemotion) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from hsemotion) (8.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from hsemotion) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from hsemotion) (0.15.2+cu118)\n",
            "Collecting timm (from hsemotion)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->hsemotion) (6.0)\n",
            "Collecting huggingface-hub (from timm->hsemotion)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm->hsemotion)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->hsemotion) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->hsemotion) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->hsemotion) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->hsemotion) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->hsemotion) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->hsemotion) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->hsemotion) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->hsemotion) (16.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->hsemotion) (2.27.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm->hsemotion) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm->hsemotion) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm->hsemotion) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->hsemotion) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->hsemotion) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->hsemotion) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->hsemotion) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->hsemotion) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->hsemotion) (1.3.0)\n",
            "Building wheels for collected packages: hsemotion\n",
            "  Building wheel for hsemotion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hsemotion: filename=hsemotion-0.3.0-py3-none-any.whl size=11242 sha256=c943aaf0044f072bcecde847f937cc3bbe03bb62047a667eb3bb521a73ad6578\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/88/e0/3b365122443c2ec55f3e058f2b7ad59df7b5e302c457c4539a\n",
            "Successfully built hsemotion\n",
            "Installing collected packages: safetensors, huggingface-hub, timm, hsemotion\n",
            "Successfully installed hsemotion-0.3.0 huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (8.4.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303886 sha256=a92f2178e6c28cfb1e0a868af63af183edf128ff2e20d04745d9ac262a08b211\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/5d/ce/bdbdb04744dac03906336eb0d01ff1e222061d3419c55c55f9\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.25.1\n",
            "    Uninstalling imageio-2.25.1:\n",
            "      Successfully uninstalled imageio-2.25.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports:\n",
        "import cv2\n",
        "import numpy as np\n",
        "from hsemotion.facial_emotions import HSEmotionRecognizer\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import (OffsetImage, AnnotationBbox)\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib import colors\n",
        "import moviepy.editor"
      ],
      "metadata": {
        "id": "EN1d2mcv3vrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da83c95c-2333-4b38-c19a-96b04e7899ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7fadb9423f40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/_weakrefset.py\", line 39, in _remove\n",
            "    def _remove(item, selfref=ref(self)):\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path video:\n",
        "path_video = \"/content/drive/MyDrive/Felicitat_10.mp4\""
      ],
      "metadata": {
        "id": "oxzfHtxz3wZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_palette = ['red', 'lawngreen', 'indigo', 'orange', 'gray', 'dodgerblue', 'hotpink']"
      ],
      "metadata": {
        "id": "HwAq3g58EU_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotions from image source:"
      ],
      "metadata": {
        "id": "sKpFVGbGVUze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subtracting frames from video"
      ],
      "metadata": {
        "id": "vDvBWVxJ3d1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture(path_video)\n",
        "\n",
        "# We get the video duration:\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "total_Frames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "duration = total_Frames/fps\n",
        "\n",
        "# Function to get frames (i.e., access the video at a given time, in seconds, \n",
        "# and get the image):\n",
        "def getFrame(video, sec):\n",
        "    video.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n",
        "    hasFrames, image = video.read()\n",
        "    image = cv2.rotate(image, cv2.ROTATE_180) # The images seem to be rotated :o.\n",
        "    return(image)\n",
        "\n",
        "# Starting at second zero:\n",
        "sec = 0\n",
        "\n",
        "# We choose a frame rate of 0.5, meaning that the function will capture an image \n",
        "# from the video in each 0.5 seconds interval (2 images per second):\n",
        "frameRate = 0.5 \n",
        "\n",
        "# We will iterativelly append each image in the frame_list, initially empty:\n",
        "frame_list = []\n",
        "while sec <= duration:\n",
        "  new_frame = getFrame(video, sec) # Getting the frame.\n",
        "  frame_list.append(new_frame) # Appending it to the list.\n",
        "  sec = sec + frameRate\n",
        "  sec = round(sec, 2)"
      ],
      "metadata": {
        "id": "ZxDOnvE63vEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "#from .padding import pad_same, get_padding_value\n",
        "\n",
        "# Dynamically pad input x with 'SAME' padding for conv with specified args\n",
        "def pad_same(x, k: List[int], s: List[int], d: List[int] = (1, 1), value: float = 0):\n",
        "    ih, iw = x.size()[-2:]\n",
        "    pad_h, pad_w = get_same_padding(ih, k[0], s[0], d[0]), get_same_padding(iw, k[1], s[1], d[1])\n",
        "    if pad_h > 0 or pad_w > 0:\n",
        "        x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
        "    return x\n",
        "\n",
        "# Calculate asymmetric TensorFlow-like 'SAME' padding for a convolution\n",
        "def get_same_padding(x: int, k: int, s: int, d: int):\n",
        "    return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
        "\n",
        "def get_padding_value(padding, kernel_size, **kwargs) -> Tuple[Tuple, bool]:\n",
        "    dynamic = False\n",
        "    if isinstance(padding, str):\n",
        "        # for any string padding, the padding will be calculated for you, one of three ways\n",
        "        padding = padding.lower()\n",
        "        if padding == 'same':\n",
        "            # TF compatible 'SAME' padding, has a performance and GPU memory allocation impact\n",
        "            if is_static_pad(kernel_size, **kwargs):\n",
        "                # static case, no extra overhead\n",
        "                padding = get_padding(kernel_size, **kwargs)\n",
        "            else:\n",
        "                # dynamic 'SAME' padding, has runtime/GPU memory overhead\n",
        "                padding = 0\n",
        "                dynamic = True\n",
        "        elif padding == 'valid':\n",
        "            # 'VALID' padding, same as padding=0\n",
        "            padding = 0\n",
        "        else:\n",
        "            # Default to PyTorch style 'same'-ish symmetric padding\n",
        "            padding = get_padding(kernel_size, **kwargs)\n",
        "    return padding, dynamic\n",
        "\n",
        "def conv2d_same(\n",
        "        x, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, stride: Tuple[int, int] = (1, 1),\n",
        "        padding: Tuple[int, int] = (0, 0), dilation: Tuple[int, int] = (1, 1), groups: int = 1):\n",
        "    x = pad_same(x, weight.shape[-2:], stride, dilation)\n",
        "    return F.conv2d(x, weight, bias, stride, (0, 0), dilation, groups)\n",
        "\n",
        "\n",
        "class Conv2dSame(nn.Conv2d):\n",
        "    \"\"\" Tensorflow like 'SAME' convolution wrapper for 2D convolutions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(Conv2dSame, self).__init__(\n",
        "            in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return conv2d_same(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "\n",
        "def create_conv2d_pad(in_chs, out_chs, kernel_size, **kwargs):\n",
        "    padding = kwargs.pop('padding', '')\n",
        "    kwargs.setdefault('bias', False)\n",
        "    padding, is_dynamic = get_padding_value(padding, kernel_size, **kwargs)\n",
        "    if is_dynamic:\n",
        "        return Conv2dSame(in_chs, out_chs, kernel_size, **kwargs)\n",
        "    else:\n",
        "        return nn.Conv2d(in_chs, out_chs, kernel_size, padding=padding, **kwargs)"
      ],
      "metadata": {
        "id": "N6lenN3o05lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image emotion predictions"
      ],
      "metadata": {
        "id": "BgrpArMS3hLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We get the total number of images captured (i.e., the length of the \n",
        "# frame_list):\n",
        "num_considered_frames = int(len(frame_list))\n",
        "\n",
        "# For each element in frame_list, we compute the emotions. The maximum value \n",
        "# each independent emotion can have is 1, an the minimum, 0. We sum each \n",
        "# independent emotion result to the overall emotional result.\n",
        "\n",
        "# The overall emotion results is a vector of the form:\n",
        "# ['Anger1', 'Anger2', ..., 'AngerN'; \n",
        "#  'Disgust1', Disgust2', ..., DisgustN':\n",
        "#  'Fear1', 'Fear2', ..., 'FearN';\n",
        "#  'Happiness1', 'Happiness2', ..., 'HappinessN';\n",
        "#  'Neutral1', 'Neutral2', ..., 'NeutralN';\n",
        "#  'Sadness1', 'Sadness2', ..., 'SadnessN';\n",
        "#  'Surprise1', 'Surprise2', ..., 'SurpriseN']\n",
        "all_emotions = np.zeros((7,num_considered_frames))\n",
        "\n",
        "# We will work with the 7 emotions' model (the one with best performance):\n",
        "model_name = 'enet_b2_7'\n",
        "f_emo_reco = HSEmotionRecognizer(model_name = model_name, device='cpu')\n",
        "\n",
        "# We set the loop and predict:\n",
        "column_count = 0\n",
        "for image in frame_list:\n",
        "  emotion, scores = f_emo_reco.predict_emotions(image, logits = False) # logits = False for ranges between 0 and 1.\n",
        "  scores = np.asarray(scores, dtype = np.float32)\n",
        "  all_emotions[:, column_count] = scores # Adding to overall emotions.\n",
        "  column_count = column_count + 1\n",
        "\n",
        "# Getting the mean value of each emotion:\n",
        "mean_all_emotions = np.zeros((7))\n",
        "for i in range(7):\n",
        "  single_emotion = all_emotions[i,:]\n",
        "  single_mean = np.mean(single_emotion)\n",
        "  mean_all_emotions[i] = single_mean\n",
        "\n",
        "# And the same for the standard deviation (SD):\n",
        "SD_all_emotions = np.zeros((7))\n",
        "for i in range(7):\n",
        "  single_emotion = all_emotions[i,:]\n",
        "  single_SD = np.std(single_emotion)\n",
        "  SD_all_emotions[i] = single_SD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "AFGQ0qab6jTC",
        "outputId": "7b4bd7ff-8493-4aaf-e17d-30b38d265986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-05b7ed54346f>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# We will work with the 7 emotions' model (the one with best performance):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'enet_b2_7'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mf_emo_reco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHSEmotionRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# We set the loop and predict:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hsemotion/facial_emotions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm.models.layers.conv2d_same'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particular plots of image analysis:"
      ],
      "metadata": {
        "id": "hncgnsxH3kZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean and std bar plot of each emotion"
      ],
      "metadata": {
        "id": "r9tdjer3-Khr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each bar of the plot corresponds to the mean of every emotion in the video:\n",
        "plt.rcParams[\"figure.figsize\"] = (15,10) \n",
        "\n",
        "F, ax = plt.subplots()\n",
        "plt.bar(np.arange(5,40,5), mean_all_emotions, yerr = SD_all_emotions, align = 'center', width = 2.2, color = color_palette, alpha = 0.7, ecolor = 'black', capsize = 4)\n",
        "custom_legend = [Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[0], alpha = 0.7, markersize=15, label=\"Anger\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[1], alpha = 0.7, markersize=15, label=\"Disgust\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[2], alpha = 0.7, markersize=15, label=\"Fear\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[3], alpha = 0.7, markersize=15, label=\"Happiness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[4], alpha = 0.7, markersize=15, label=\"Neutral\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[5], alpha = 0.7, markersize=15, label=\"Sadness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[6], alpha = 0.7, markersize=15, label=\"Surprise\")]\n",
        "ax.legend(handles = custom_legend, prop = {'size': 15})\n",
        "\n",
        "plt.xlabel(\"Emotions\", fontsize = 28)\n",
        "plt.ylabel(\"Emotion intensity\", fontsize = 28)\n",
        "plt.title(\"Emotional $\\mu$ and $\\sigma$ captured in video images\", fontsize = 35)\n",
        "plt.ylim([0,1])\n",
        "ax.axes.xaxis.set_ticklabels([])\n",
        "plt.savefig(\"/content/drive/MyDrive/bar_emotions.png\")\n",
        "plt.show()\n",
        "\n",
        "# We reset the figure size:\n",
        "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-A2P972b-Pbg",
        "outputId": "73f03911-5166-46b1-9c63-83756f4bb674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f68b3432c6e0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_all_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSD_all_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_palette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m custom_legend = [Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[0], alpha = 0.7, markersize=15, label=\"Anger\"),\n\u001b[1;32m      7\u001b[0m                  \u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkerfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Disgust\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mean_all_emotions' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Line plot of emotions during the image sequences"
      ],
      "metadata": {
        "id": "RYv0rrb1_rCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each line in the plot corresponds to the value of each captured emotion \n",
        "# during the video, so some sort of emotional progression during it can be seen:\n",
        "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "F,ax = plt.subplots()\n",
        "for i in range(7):\n",
        "  plt.plot(np.arange(num_considered_frames), all_emotions[i,:],  'o-', color = color_palette[i], alpha = 0.7, LineWidth = 4)\n",
        "plt.xlabel(\"Video frame\", fontsize = 15)\n",
        "plt.xticks(np.arange(num_considered_frames))\n",
        "plt.ylabel(\"Emotion intensity\", fontsize = 15)\n",
        "plt.title(\"Emotion progression in video\", fontsize = 25)\n",
        "plt.ylim([0,1])\n",
        "custom_legend = [Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[0], alpha = 0.7, markersize=15, label=\"Anger\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[1], alpha = 0.7, markersize=15, label=\"Disgust\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[2], alpha = 0.7, markersize=15, label=\"Fear\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[3], alpha = 0.7, markersize=15, label=\"Happiness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[4], alpha = 0.7, markersize=15, label=\"Neutral\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[5], alpha = 0.7, markersize=15, label=\"Sadness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[6], alpha = 0.7, markersize=15, label=\"Surprise\")]\n",
        "ax.legend(handles = custom_legend, prop = {'size': 12})\n",
        "\n",
        "plt.savefig(\"/content/drive/MyDrive/line_emotions.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ClyoB9MJ_tu2",
        "outputId": "7e6d3ce2-c5ac-4d6f-b762-3a2981a71df7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b6014616cec6>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_considered_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_emotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'o-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_palette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLineWidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Video frame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_considered_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         result = (make_artist(x[:, j % ncx], y[:, j % ncy], kw,\n\u001b[0m\u001b[1;32m    538\u001b[0m                               {**kwargs, 'label': label})\n\u001b[1;32m    539\u001b[0m                   for j, label in enumerate(labels))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[0;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlack\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprenormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaintain\u001b[0m \u001b[0mbackcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{cls.__name__}.set() got an unexpected keyword argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \"{prop_name!r}\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1195\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"set_{k}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                         raise AttributeError(\n\u001b[0m\u001b[1;32m   1198\u001b[0m                             errfmt.format(cls=type(self), prop_name=k))\n\u001b[1;32m   1199\u001b[0m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Line2D.set() got an unexpected keyword argument 'LineWidth'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image frames dominant emotion plot"
      ],
      "metadata": {
        "id": "q6mY0fXva9jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to make a plot in a similar manner that the one above, but with the \n",
        "# exception of showing which emotion is the most relevant in each frame, as well \n",
        "# as displaying frame miniatures in each case.\n",
        "\n",
        "# To do so, we create a matrix:\n",
        "emotion_matrix = np.zeros((round(num_considered_frames/2.5),num_considered_frames))\n",
        "for row_emotions in range(all_emotions.shape[1]):\n",
        "  emotions_frame = all_emotions[:,row_emotions]\n",
        "  emotion_matrix[:,row_emotions] = int(np.where(emotions_frame == np.max(emotions_frame))[0])\n",
        "\n",
        "# Creating the matrix color map:\n",
        "cmap = colors.ListedColormap(color_palette)\n",
        "\n",
        "# Image representation:\n",
        "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "\n",
        "F, ax = plt.subplots()\n",
        "plt.imshow(emotion_matrix, cmap = cmap, alpha = 0.7, vmin = 0, vmax = 6)\n",
        "\n",
        "for j in range(num_considered_frames):\n",
        "  plt.axvline(x = int(j), color = 'black', linestyle = '--', alpha = 0.8)\n",
        "\n",
        "for i in range(num_considered_frames):\n",
        "  icon = frame_list[i]\n",
        "  icon = cv2.cvtColor(icon, cv2.COLOR_BGR2RGB)\n",
        "  imagebox = OffsetImage(icon, zoom = 0.035)\n",
        "  ab = AnnotationBbox(imagebox, (i, 0.5), frameon = False)\n",
        "  ax.add_artist(ab)\n",
        "\n",
        "plt.xlim([-1,num_considered_frames])\n",
        "plt.title(\"Dominant emotion per frame\", fontsize = 25)\n",
        "plt.axis(\"off\")\n",
        "custom_legend = [Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[0], alpha = 0.7, markersize=15, label=\"Anger\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[1], alpha = 0.7, markersize=15, label=\"Disgust\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[2], alpha = 0.7, markersize=15, label=\"Fear\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[3], alpha = 0.7, markersize=15, label=\"Happiness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[4], alpha = 0.7, markersize=15, label=\"Neutral\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[5], alpha = 0.7, markersize=15, label=\"Sadness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[6], alpha = 0.7, markersize=15, label=\"Surprise\")]\n",
        "ax.legend(handles = custom_legend, loc = \"lower right\", prop = {'size': 8})\n",
        "\n",
        "plt.savefig(\"/content/drive/MyDrive/matrix_emotions.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "QIV835MsbG8b",
        "outputId": "379700b2-37c6-4519-a08a-c2475b682cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-467e53926eba>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow_emotions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_emotions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0memotions_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_emotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow_emotions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0memotion_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow_emotions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotions_frame\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotions_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Creating the matrix color map:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotions from audio source:"
      ],
      "metadata": {
        "id": "k3dutK5hWLvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subtracting audio from video"
      ],
      "metadata": {
        "id": "S7WIJ-LIYZup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For audio subtraction, the video must be subtracted using the moviepy module:\n",
        "video = moviepy.editor.VideoFileClip(path_video)\n",
        "audio = video.audio\n",
        "# Creo que con estas pocas líneas ya tendrás el audio :)"
      ],
      "metadata": {
        "id": "AJb_5J8RYcZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio emotion predictions:"
      ],
      "metadata": {
        "id": "Gg500B84WPB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "mean_audio = np.zeros((7))\n",
        "\n"
      ],
      "metadata": {
        "id": "Mw9qRPW-Waw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particular plots of audio analysis:"
      ],
      "metadata": {
        "id": "bhzJFrfyWbGy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHXKrfFDWeoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined prediction:"
      ],
      "metadata": {
        "id": "yQIWT6BTWlqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Each bar of the plot corresponds to the averaged mean of every emotion in the \n",
        "# video:\n",
        "plt.rcParams[\"figure.figsize\"] = (15,10) \n",
        "\n",
        "F, ax = plt.subplots()\n",
        "plt.bar(np.arange(5,40,5), combined_mean_emotions, align = 'center', width = 2.2, color = color_palette, alpha = 0.7)\n",
        "custom_legend = [Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[0], alpha = 0.7, markersize=15, label=\"Anger\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[1], alpha = 0.7, markersize=15, label=\"Disgust\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[2], alpha = 0.7, markersize=15, label=\"Fear\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[3], alpha = 0.7, markersize=15, label=\"Happiness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[4], alpha = 0.7, markersize=15, label=\"Neutral\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[5], alpha = 0.7, markersize=15, label=\"Sadness\"),\n",
        "                 Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[6], alpha = 0.7, markersize=15, label=\"Surprise\")]\n",
        "ax.legend(handles = custom_legend, prop = {'size': 15})\n",
        "\n",
        "plt.xlabel(\"Emotions\", fontsize = 28)\n",
        "plt.ylabel(\"Averaged emotion prediction\", fontsize = 28)\n",
        "plt.title(\"Average emotions captured in video (combined prediction)\", fontsize = 35)\n",
        "plt.ylim([0,1])\n",
        "ax.axes.xaxis.set_ticklabels([])\n",
        "plt.savefig(\"/content/drive/MyDrive/average_bar_emotions.png\")\n",
        "plt.show()\n",
        "\n",
        "# We reset the figure size:\n",
        "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PZmFTytSWpJs",
        "outputId": "8f778a74-d2b0-4a8a-b383-ab8626cd62c3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f296400b8334>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mean_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_palette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m custom_legend = [Line2D([0], [0], marker='o', color='white', markerfacecolor=color_palette[0], alpha = 0.7, markersize=15, label=\"Anger\"),\n\u001b[1;32m      8\u001b[0m                  \u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkerfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Disgust\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'combined_mean_emotions' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}